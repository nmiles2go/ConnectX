{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "!pip -q install ibm-watson-machine-learning\n!pip -q install --upgrade ibm-watson-machine-learning", "metadata": {"id": "3f770010-e993-4b54-8b3d-1fc5aa35cdd8"}, "outputs": [], "execution_count": 37}, {"cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nfrom ibm_watson_machine_learning.metanames import AIServiceMetaNames\n\nfrom pathlib import Path\nimport importlib.util, sys\nimport os, json, textwrap, datetime\n\nAPI_KEY  = \"zIyqNeDQ6Tkxilnpu-Sep0h4lX-kvEQP6-Z-LTZ5WpO4\"     # <-- paste\nSPACE_ID = \"3dc35720-1a75-4e5f-a08e-f95f5eddb711\"\nURL      = \"https://us-south.ml.cloud.ibm.com\"\n\nwml_credentials = {\"url\": URL, \"apikey\": API_KEY}\nclient = APIClient(wml_credentials)\n\n# Set default space so store/deploy calls go to it\nclient.set.default_space(SPACE_ID)\nprint(\"Using space:\", SPACE_ID)\n", "metadata": {"id": "56a43535-cbc2-41dc-ba2f-df43653f3611"}, "outputs": [{"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)", "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mibm_watson_machine_learning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m APIClient\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mibm_watson_machine_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetanames\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AIServiceMetaNames\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msys\u001b[39;00m\n", "\u001b[0;31mImportError\u001b[0m: cannot import name 'AIServiceMetaNames' from 'ibm_watson_machine_learning.metanames' (/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watson_machine_learning/metanames.py)"], "ename": "ImportError", "evalue": "cannot import name 'AIServiceMetaNames' from 'ibm_watson_machine_learning.metanames' (/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watson_machine_learning/metanames.py)", "output_type": "error"}], "execution_count": 38}, {"cell_type": "code", "source": "import os, types\nimport pandas as pd\nimport numpy as np\nfrom botocore.client import Config\nimport ibm_boto3\nimport re\nimport base64, json, requests\n\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='rMxogpL4qsgtt0qT45To_N0q9iJp0gzili8mIWLk1RYr',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/identity/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.direct.us-south.cloud-object-storage.appdomain.cloud')\n\nbucket = 'riyassandbox-donotdelete-pr-spbpwn7zrlpz1g'\nobject_key = 'connectX.csv'\n\nbody = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.info()", "metadata": {"id": "3503d8ac-8fb5-4fca-bf7b-77fa4ab0f2bf"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500 entries, 0 to 499\nData columns (total 19 columns):\n #   Column                         Non-Null Count  Dtype  \n---  ------                         --------------  -----  \n 0   region_id                      500 non-null    object \n 1   region_name                    500 non-null    object \n 2   state                          500 non-null    object \n 3   population                     500 non-null    float64\n 4   households                     500 non-null    float64\n 5   population_density_km2         500 non-null    float64\n 6   median_income_usd              500 non-null    float64\n 7   education_index                500 non-null    float64\n 8   urban_rural_flag               500 non-null    object \n 9   dsl_coverage_pct               500 non-null    float64\n 10  avg_dsl_speed_mbps             500 non-null    float64\n 11  competitor_fiber_presence      500 non-null    int64  \n 12  complaint_rate_pct             500 non-null    float64\n 13  churn_rate_pct                 500 non-null    float64\n 14  broadband_adoption_pct         500 non-null    float64\n 15  avg_monthly_data_gb            500 non-null    float64\n 16  terrain_slope_deg              500 non-null    float64\n 17  road_density_km_per_km2        500 non-null    float64\n 18  existing_backhaul_distance_km  500 non-null    float64\ndtypes: float64(14), int64(1), object(4)\nmemory usage: 74.3+ KB\n"}], "execution_count": 17}, {"cell_type": "code", "source": "def score_take_rate(r):\n    adoption = nz(r[\"broadband_adoption_pct\"], 60) / 100\n    income   = nz(r[\"median_income_usd\"], 55000)\n    income_norm = clamp((income - 30000) / 60000, 0, 1)\n    comp_penalty      = 0.06 * nz(r[\"competitor_fiber_presence\"], 0)\n    complaint_penalty = nz(r[\"complaint_rate_pct\"], 6) / 200\n    urban_bonus = 0.05 if nz(r[\"urban_rural_flag\"], \"Rural\") == \"Urban\" else 0\n    take = 100 * clamp(0.25 + 0.5*adoption + 0.2*income_norm + urban_bonus\n                       - comp_penalty - complaint_penalty, 0.05, 0.9)\n    return round(take, 1)\n\ndef estimate_capex(r):\n    density  = nz(r[\"population_density_km2\"], 200)\n    slope    = nz(r[\"terrain_slope_deg\"], 3)\n    backhaul = nz(r[\"existing_backhaul_distance_km\"], 3)\n    urban    = 1 if nz(r[\"urban_rural_flag\"], \"Rural\") == \"Urban\" else 0\n    capex = (1600\n             + 220 * (1 / (1 + density/250))\n             + 25 * slope\n             + 90 * backhaul\n             + 250 * (1 - urban))\n    return round(capex, 2)\n\ndef predict_roi(r, take_rate, capex):\n    arpu, opex_pct = 75.0, 0.35\n    homes = max(1, int(nz(r[\"households\"], 1)))\n    subs = homes * (take_rate/100.0)\n    annual_rev  = subs * arpu * 12\n    annual_opex = annual_rev * opex_pct\n    annual_cf   = max(1e-6, annual_rev - annual_opex)\n    total_capex = homes * capex\n    payback = total_capex / annual_cf\n    roi3 = (3*annual_cf - total_capex) / max(1.0, total_capex) * 100\n    return round(payback, 2), round(roi3, 1)\n\ndef priority_score(r):\n    take = clamp(nz(r[\"take_rate_pct\"], 0) / 80, 0, 1)\n    roi  = clamp((nz(r[\"roi_3yr_pct\"], -50) + 50) / 150, 0, 1)\n    cap  = clamp(1 - (nz(r[\"capex_per_premise_usd\"], 3200) - 1200) / 2000, 0, 1)\n    comp = clamp(1 - nz(r[\"competitor_fiber_presence\"], 0) / 3, 0, 1)\n    ready = 0.6\n    return round(0.30*take + 0.30*roi + 0.25*cap + 0.10*comp + 0.05*ready, 3)\n\ndef assign_phase_row(r):\n    if r[\"priority_score\"] >= 0.80 and r[\"payback_years\"] <= 5.0 and r[\"capex_per_premise_usd\"] <= 2000:\n        return \"Pilot\"\n    elif r[\"priority_score\"] >= 0.65 and r[\"payback_years\"] <= 5.0 and r[\"capex_per_premise_usd\"] <= 2000:\n        return \"Phase 1\"\n    elif r[\"payback_years\"] <= 6.5 and r[\"capex_per_premise_usd\"] <= 2600:\n        return \"Phase 2\"\n    else:\n        return \"Defer\"\n\ndef nz(x, default):\n    return default if pd.isna(x) else x\n\ndef clamp(x, lo, hi): \n    try:\n        x = float(x)\n    except Exception:\n        return lo\n    return max(lo, min(hi, x))", "metadata": {"id": "20cccc00-33cd-4f23-bf9f-40ad5b2deeaa"}, "outputs": [], "execution_count": 15}, {"cell_type": "code", "source": "code = \"\"\"\nimport pandas as pd\n\ndef nz(x, default):\n    return default if pd.isna(x) else x\n\ndef clamp(x, lo, hi): \n    try:\n        x = float(x)\n    except Exception:\n        return lo\n    return max(lo, min(hi, x))\n\ndef score_take_rate(r):\n    adoption = nz(r.get(\"broadband_adoption_pct\"), 60) / 100\n    income   = nz(r.get(\"median_income_usd\"), 55000)\n    income_norm = clamp((income - 30000) / 60000, 0, 1)\n    comp_penalty      = 0.06 * nz(r.get(\"competitor_fiber_presence\"), 0)\n    complaint_penalty = nz(r.get(\"complaint_rate_pct\"), 6) / 200\n    urban_bonus = 0.05 if nz(r.get(\"urban_rural_flag\"), \"Rural\") == \"Urban\" else 0\n    take = 100 * clamp(0.25 + 0.5*adoption + 0.2*income_norm + urban_bonus\n                       - comp_penalty - complaint_penalty, 0.05, 0.9)\n    return round(take, 1)\n\ndef estimate_capex(r):\n    density  = nz(r.get(\"population_density_km2\"), 200)\n    slope    = nz(r.get(\"terrain_slope_deg\"), 3)\n    backhaul = nz(r.get(\"existing_backhaul_distance_km\"), 3)\n    urban    = 1 if nz(r.get(\"urban_rural_flag\"), \"Rural\") == \"Urban\" else 0\n    capex = (1600 + 220 * (1 / (1 + density/250)) + 25 * slope + 90 * backhaul + 250 * (1 - urban))\n    return round(capex, 2)\n\ndef predict_roi(r, take_rate, capex):\n    arpu, opex_pct = 75.0, 0.35\n    homes = max(1, int(nz(r.get(\"households\"), 1)))\n    subs = homes * (take_rate/100.0)\n    annual_rev  = subs * arpu * 12\n    annual_opex = annual_rev * opex_pct\n    annual_cf   = max(1e-6, annual_rev - annual_opex)\n    total_capex = homes * capex\n    payback = total_capex / annual_cf\n    roi3 = (3*annual_cf - total_capex) / max(1.0, total_capex) * 100\n    return round(payback, 2), round(roi3, 1)\n\ndef priority_score(r):\n    take = clamp(nz(r.get(\"take_rate_pct\"), 0) / 80, 0, 1)\n    roi  = clamp((nz(r.get(\"roi_3yr_pct\"), -50) + 50) / 150, 0, 1)\n    cap  = clamp(1 - (nz(r.get(\"capex_per_premise_usd\"), 3200) - 1200) / 2000, 0, 1)\n    comp = clamp(1 - nz(r.get(\"competitor_fiber_presence\"), 0) / 3, 0, 1)\n    ready = 0.6\n    return round(0.30*take + 0.30*roi + 0.25*cap + 0.10*comp + 0.05*ready, 3)\n\ndef assign_phase_row(r):\n    if r[\"priority_score\"] >= 0.80 and r[\"payback_years\"] <= 5.0 and r[\"capex_per_premise_usd\"] <= 2000:\n        return \"Pilot\"\n    elif r[\"priority_score\"] >= 0.65 and r[\"payback_years\"] <= 5.0 and r[\"capex_per_premise_usd\"] <= 2000:\n        return \"Phase 1\"\n    elif r[\"payback_years\"] <= 6.5 and r[\"capex_per_premise_usd\"] <= 2600:\n        return \"Phase 2\"\n    else:\n        return \"Defer\"\n\ndef connectx_service(context, params=None, **custom):\n    # ONLINE inference entrypoint:\n    def generate(context) -> dict:\n        body = context.get_json() or {}\n        path = body.get(\"path\", \"/priority\")\n        regions = body.get(\"regions\", [])\n        out = []\n\n        for r in regions:\n            if path == \"/take-rate\":\n                out.append({\"region_id\": r.get(\"region_id\"), \"take_rate_pct\": score_take_rate(r)})\n            elif path == \"/capex\":\n                out.append({\"region_id\": r.get(\"region_id\"), \"capex_per_premise_usd\": estimate_capex(r)})\n            elif path == \"/roi\":\n                take = score_take_rate(r); capex = estimate_capex(r)\n                payback, roi3 = predict_roi(r, take, capex)\n                out.append({\"region_id\": r.get(\"region_id\"),\n                            \"take_rate_pct\": take, \"capex_per_premise_usd\": capex,\n                            \"payback_years\": payback, \"roi_3yr_pct\": roi3})\n            elif path == \"/priority\":\n                take = score_take_rate(r); capex = estimate_capex(r)\n                payback, roi3 = predict_roi(r, take, capex)\n                rlocal = {\"take_rate_pct\": take, \"capex_per_premise_usd\": capex,\n                          \"payback_years\": payback, \"roi_3yr_pct\": roi3,\n                          \"competitor_fiber_presence\": r.get(\"competitor_fiber_presence\")}\n                out.append({\"region_id\": r.get(\"region_id\"),\n                            \"priority_score\": priority_score(rlocal)})\n            elif path == \"/phase\":\n                take = score_take_rate(r); capex = estimate_capex(r)\n                payback, roi3 = predict_roi(r, take, capex)\n                rlocal = {\"take_rate_pct\": take, \"capex_per_premise_usd\": capex,\n                          \"payback_years\": payback, \"roi_3yr_pct\": roi3,\n                          \"competitor_fiber_presence\": r.get(\"competitor_fiber_presence\")}\n                phase = assign_phase_row({\"priority_score\": priority_score(rlocal),\n                                          \"payback_years\": payback,\n                                          \"capex_per_premise_usd\": capex})\n                out.append({\"region_id\": r.get(\"region_id\"), \"phase\": phase})\n            else:\n                out.append({\"region_id\": r.get(\"region_id\"), \"error\": f\"Unknown path {path}\"})\n\n        return {\"path\": path, \"results\": out}\n\"\"\"\nwith open(\"connectX_tools.py\", \"w\") as f:\n    f.write(code)\nprint(\"Wrote connectX_tools.py\")", "metadata": {"id": "b56cc2ba-3c90-4ed2-ac45-1cf389129396"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Wrote connectX_tools.py\n"}], "execution_count": 26}, {"cell_type": "code", "source": "import tarfile\n\nwith tarfile.open(\"fiber_function.tar.gz\", \"w:gz\") as tar:\n    tar.add(\"connectX_tools.py\", arcname=\"connectX_tools.py\")\n\nprint(\"Created fiber_function.tar.gz\")", "metadata": {"id": "77b48540-219a-45f2-8019-1090760e7098"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Created fiber_function.tar.gz\n"}], "execution_count": 27}, {"cell_type": "code", "source": "r = requests.post(\n    \"https://iam.cloud.ibm.com/identity/token\",\n    headers={\"Content-Type\":\"application/x-www-form-urlencoded\"},\n    data={\"grant_type\":\"urn:ibm:params:oauth:grant-type:apikey\",\"apikey\":API_KEY}\n)\ntoken = r.json()[\"access_token\"]\nprint(\"Got IAM token \u2714\")", "metadata": {"id": "114476a1-3d76-4288-a1f3-61b4871ebfb3"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Got IAM token \u2714\n"}], "execution_count": 28}, {"cell_type": "code", "source": "with open(\"function.tar.gz\", \"rb\") as f:\n    b64 = base64.b64encode(f.read()).decode(\"utf-8\")", "metadata": {"id": "f6548e6f-47f6-4209-abbb-d1e00f78ecad"}, "outputs": [], "execution_count": 18}, {"cell_type": "code", "source": "SPACE_ID  = \"3dc35720-1a75-4e5f-a08e-f95f5eddb711\"         # from your Developer access card\nPROJECT_ID= \"08ce3da9-7da1-440b-9dc0-d6654da40a43\"                            # from the same card (shown in your screenshot)\nURL       = \"https://us-south.ml.cloud.ibm.com\"\nVERSION   = \"2024-08-01\"  ", "metadata": {"id": "9375bfb9-be43-4720-a0dd-3523e3110ec6"}, "outputs": [], "execution_count": 24}, {"cell_type": "code", "source": "client = APIClient({\"url\": URL, \"apikey\": API_KEY})\nclient.set.default_space(SPACE_ID)\nclient.set.default_project(PROJECT_ID)\n\n# 2.1 Load the function symbol from ai_service.py\nspec = importlib.util.spec_from_file_location(\"ai_mod\", \"connectX_tools.py\")\nai_mod = importlib.util.module_from_spec(spec)\nsys.modules[\"ai_mod\"] = ai_mod\nspec.loader.exec_module(ai_mod)\n\nSSPEC_ID = client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")  # or another shown in the list\n", "metadata": {"id": "e7ff2627-8728-4fc6-a4fc-034d25d5b373"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Unsetting the space_id ...\n"}], "execution_count": 35}, {"cell_type": "code", "source": "", "metadata": {"id": "337abdb3-d4be-4c37-9f4e-8c8dfcdf7dda"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "meta = {\n    client.repository.ModelMetaNames.NAME: \"connectX-tools\",\n    client.repository.ModelMetaNames.TYPE: \"function\",\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\n}\nmodel_id = client.repository.store_model(model=\"connectX_tools.py\", meta_props=meta)\nprint(\"MODEL_ID:\", model_id)\n", "metadata": {"id": "85dfd260-d7d2-4fd8-a024-4b09b8c28554"}, "outputs": [{"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)", "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m meta \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     client\u001b[38;5;241m.\u001b[39mrepository\u001b[38;5;241m.\u001b[39mAIServiceMetaNames\u001b[38;5;241m.\u001b[39mNAME: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnectX-fiber-ai-service\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     client\u001b[38;5;241m.\u001b[39mrepository\u001b[38;5;241m.\u001b[39mAIServiceMetaNames\u001b[38;5;241m.\u001b[39mSOFTWARE_SPEC_ID: SSPEC_ID,\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m stored \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mrepository\u001b[38;5;241m.\u001b[39mstore_ai_service(ai_mod\u001b[38;5;241m.\u001b[39mconnectx_service, meta)\n\u001b[1;32m      6\u001b[0m ai_service_id \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mrepository\u001b[38;5;241m.\u001b[39mget_ai_service_id(stored)\n", "\u001b[0;31mAttributeError\u001b[0m: 'Repository' object has no attribute 'AIServiceMetaNames'"], "ename": "AttributeError", "evalue": "'Repository' object has no attribute 'AIServiceMetaNames'", "output_type": "error"}], "execution_count": 36}, {"cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\n\nclient = APIClient({\"url\": \"https://us-south.ml.cloud.ibm.com\", \"apikey\": \"zIyqNeDQ6Tkxilnpu-Sep0h4lX-kvEQP6-Z-LTZ5WpO4\"})\nclient.set.default_space(\"3dc35720-1a75-4e5f-a08e-f95f5eddb711\")\n\nmeta = {\n  client.repository.ModelMetaNames.NAME: \"connectX-tools\",\n  client.repository.ModelMetaNames.TYPE: \"function\",\n  client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\n}\n\n# model_id = client.repository.store_model(model=\"connectX_tools.py\", meta_props=meta)\n# deployment = client.deployments.create(artifact_uid=model_id, meta_props={client.deployments.ConfigurationMetaNames.NAME: \"connectX-tools-api\"})\n# print(client.deployments.get_scoring_href(deployment))\n\nmodel_id = client.repository.store_model(model=\"connectX_tools.py\", meta_props=meta)\n\ndep = client.deployments.create(\n    artifact_uid=model_id,\n    meta_props={client.deployments.ConfigurationMetaNames.NAME: \"connectX-tools-api\"}\n)\ndeployment_id = client.deployments.get_id(dep)\nscoring_url = client.deployments.get_scoring_href(dep)\ndeployment_id, scoring_url\n", "metadata": {"id": "46e417b2-daec-4c63-be8a-3b401e6f4c7b"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "df[\"take_rate_pct\"] = df.apply(score_take_rate, axis=1)\ndf[\"capex_per_premise_usd\"] = df.apply(estimate_capex, axis=1)\ndf[[\"payback_years\",\"roi_3yr_pct\"]] = df.apply(\n    lambda r: pd.Series(predict_roi(r, r[\"take_rate_pct\"], r[\"capex_per_premise_usd\"])),\n    axis=1\n)\ndf[\"priority_score\"] = df.apply(priority_score, axis=1)\ndf = df.sort_values(\"priority_score\", ascending=False).reset_index(drop=True)\ndf[\"priority_rank\"] = df.index + 1\ndf[\"phase\"] = df.apply(assign_phase_row, axis=1)\ndf.head(10)", "metadata": {"id": "28b90011-a922-49e2-a694-01585b9095cd"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "df.describe()[[\"take_rate_pct\",\"capex_per_premise_usd\",\"payback_years\",\"roi_3yr_pct\",\"priority_score\"]]", "metadata": {"id": "0293b995-4e52-4e37-9c14-3cca1dae545d"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "connectX_output_data = df.to_csv(\"connectX_data_output.csv\",index=False)\ntry:\n    cos_client.upload_file(Filename=\"connectX_output_data\", Bucket=bucket, Key=object_key)\n    print(f\"File '{file_name}' uploaded to '{object_key}' in bucket '{bucket_name}'.\")\nexcept Exception as e:\n    print(f\"Error uploading file: {e}\")\n    \n", "metadata": {"id": "49edea56-0d17-4a4e-a753-fafccae6d691"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "f430f48a-5f51-4400-8a57-f00c06204e5d"}, "outputs": [], "execution_count": null}]}